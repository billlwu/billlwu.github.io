---
title: ML thoughts
---

2020/Dec

[Artificial Intelligence - The Revolution hasnâ€™t Happened Yet](https://hdsr.mitpress.mit.edu/pub/wot7mkc1/release/9), by Michael I. Jordan (statistic/CS prof from Berkeley; Andrew Ng was his PhD student)

Some key points:
- AI is partly ML (early 1990s: would grow into industrial relevance; early 2000s: fraud detection, supply-chain prediction, recommendation systems at tech firms; eventually: robust ML systems will power all companies in which decision is powered by large-scale data)
- Past 20 years saw progress in Intelligence Augmentation IA: think search engine (augments human memory and factual knowledge), computer-based generation of sounds and images (serves as palette and creativity enhance for artists)
- Another relevant domain is Intelligent Infrastructure II: a web of computation, data, physical entities that makes human environments more supportive, interesting, and safe.
- Currently, state-of-the-art AI is low-level (gather data + deep learning to create a system that mimics some narrowly-defined human skill). They focus on the ability to recognize patterns, control movements, make predictions. Success in areas like computer vision, speech recognition, game-playing, robotics is 1) overhyped and 2) neither sufficient nor necessary to solve IA and II problems.
    - Sufficiency: to apply self-driving cars in society, there is an abundance of engineering problems to be solved: we need to upgrade the overall transportation system to more closely resemble an air-traffic control system. This is arguably more pressing than human-imitative AI. 
    - Necessity: human intelligence is the only kind we've biologically evolved into, but it might not be good at figuring out the large-scale decision making that modern II systems face. 
- The challenges facing human-imitative AI and developing II are not aligned (really good para on this)
- integrating AI, II, IA into a broad engineering domain is the problem we should try and solve, and let's not loose focus.
